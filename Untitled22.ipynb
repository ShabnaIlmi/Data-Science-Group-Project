{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lC38RexCr--rgkjA-4Ks4MmCq0c4czfX",
      "authorship_tag": "ABX9TyMJhrgCdoP3f9JsPyejW1OK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShabnaIlmi/Data-Science-Group-Project/blob/recipe-risk-analyzer/Untitled22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the dataset\n",
        "#file_path = \"chemical_recipe_dataset.csv\"  # Replace with the actual file path if necessary\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/CW_ML/chemical_recipe_dataset.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDxj3WzhPB2R",
        "outputId": "12728371-be09-46fe-da73-d1fa7c42cbc5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Recipe ID                                     Chemical Names  \\\n",
            "0     R0001  Acetone + Hydrogen Peroxide + Sulfuric Acid + ...   \n",
            "1     R0002              Charcoal + Potassium Nitrate + Sulfur   \n",
            "2     R0003                         Hydrogen Sulfide + Ammonia   \n",
            "3     R0004                          Sulfur + Ammonium Nitrate   \n",
            "4     R0005    Hydrogen Sulfide + Ammonia + Methane + Chlorine   \n",
            "\n",
            "                  Quantities   Category  \\\n",
            "0  485g + 398g + 275g + 197g  Explosive   \n",
            "1          465g + 134g + 72g  Explosive   \n",
            "2                272g + 358g  Corrosive   \n",
            "3                297g + 304g   Unstable   \n",
            "4   74g + 376g + 285g + 199g  Corrosive   \n",
            "\n",
            "                                 Potential Reaction Risk Level  \n",
            "0   Explosion risk when exposed to heat or friction        Low  \n",
            "1   Explosion risk when exposed to heat or friction     Medium  \n",
            "2                    Causes severe burns on contact     Medium  \n",
            "3  May decompose violently under certain conditions       High  \n",
            "4                    Causes severe burns on contact     Medium  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "# Train Word2Vec on chemical names\n",
        "chemicals_list = [chem.split(\" + \") for chem in data[\"Chemical Names\"]]\n",
        "w2v_model = gensim.models.Word2Vec(chemicals_list, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Convert chemicals into word embeddings\n",
        "def get_embedding(sentence):\n",
        "    words = sentence.split(\" + \")\n",
        "    return sum([w2v_model.wv[word] for word in words if word in w2v_model.wv] or [np.zeros(100)]) / len(words)\n",
        "\n",
        "data[\"Chemical_Embeddings\"] = data[\"Chemical Names\"].apply(get_embedding)\n"
      ],
      "metadata": {
        "id": "QJ0JBjRvSdMf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eEt00OdOBET"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Initialize Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "\n",
        "# Fit tokenizer on text data\n",
        "tokenizer.fit_on_texts(data[\"Chemical Names\"] + data[\"Potential Reaction\"])\n",
        "\n",
        "# Convert text to sequences\n",
        "chemical_sequences = tokenizer.texts_to_sequences(data[\"Chemical Names\"])\n",
        "reaction_sequences = tokenizer.texts_to_sequences(data[\"Potential Reaction\"])\n",
        "\n",
        "# Pad sequences to ensure uniform shape\n",
        "chemical_padded = pad_sequences(chemical_sequences, maxlen=10, padding=\"post\")\n",
        "reaction_padded = pad_sequences(reaction_sequences, maxlen=20, padding=\"post\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Extract and normalize Quantities\n",
        "data[\"Quantities_Sum\"] = data[\"Quantities\"].str.extractall(r\"(\\d+)\").astype(float).groupby(level=0).sum()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "quantities_scaled = scaler.fit_transform(data[\"Quantities_Sum\"].values.reshape(-1, 1))\n"
      ],
      "metadata": {
        "id": "65KlsXU8QF90"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode Risk Level (Target)\n",
        "label_encoder = LabelEncoder()\n",
        "y_lstm = label_encoder.fit_transform(data[\"Risk Level\"])\n"
      ],
      "metadata": {
        "id": "Skz55UB5QT_5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all processed features into a single dataset\n",
        "X_lstm = np.hstack((chemical_padded, reaction_padded, quantities_scaled))\n"
      ],
      "metadata": {
        "id": "Zg0gDkBDQpy2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_lstm = X_lstm.reshape(X_lstm.shape[0], X_lstm.shape[1], 1)  # Add 3rd dimension for LSTM\n"
      ],
      "metadata": {
        "id": "WLeSkt8RQtWy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "# Define CNN + LSTM model\n",
        "model = Sequential([\n",
        "    Conv1D(64, kernel_size=3, activation=\"relu\", input_shape=(X_lstm.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3),\n",
        "    LSTM(128, dropout=0.3),\n",
        "\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(np.unique(y_lstm)), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train model with more epochs and early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_lstm, y_lstm, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk7nFT4aTNPj",
        "outputId": "1dd41493-84af-4dac-898d-3fc45d45dba6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.3485 - loss: 1.1101 - val_accuracy: 0.3150 - val_loss: 1.1180\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.3132 - loss: 1.1182 - val_accuracy: 0.3400 - val_loss: 1.1000\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.3341 - loss: 1.1018 - val_accuracy: 0.3400 - val_loss: 1.1014\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 0.3347 - loss: 1.1010 - val_accuracy: 0.3300 - val_loss: 1.1009\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.3506 - loss: 1.0993 - val_accuracy: 0.3500 - val_loss: 1.0972\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - accuracy: 0.3444 - loss: 1.0996 - val_accuracy: 0.3400 - val_loss: 1.1001\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.3642 - loss: 1.0984 - val_accuracy: 0.3450 - val_loss: 1.0976\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.3975 - loss: 1.0957 - val_accuracy: 0.3200 - val_loss: 1.0982\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.3281 - loss: 1.1061 - val_accuracy: 0.3200 - val_loss: 1.1004\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.3596 - loss: 1.0979 - val_accuracy: 0.3350 - val_loss: 1.0977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aab4435aa90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Define LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(X_lstm.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(len(np.unique(y_lstm)), activation=\"softmax\")  # Multi-class classification\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_lstm, y_lstm, epochs=20, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cjg5YNRfQxnH",
        "outputId": "b6354eb6-e90f-492f-8cd3-f08eee595a6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.3510 - loss: 1.0998 - val_accuracy: 0.3400 - val_loss: 1.0985\n",
            "Epoch 2/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.3250 - loss: 1.1012 - val_accuracy: 0.3400 - val_loss: 1.0976\n",
            "Epoch 3/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.3687 - loss: 1.1004 - val_accuracy: 0.3150 - val_loss: 1.0989\n",
            "Epoch 4/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.2806 - loss: 1.1000 - val_accuracy: 0.3650 - val_loss: 1.0985\n",
            "Epoch 5/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.3467 - loss: 1.0987 - val_accuracy: 0.3450 - val_loss: 1.0974\n",
            "Epoch 6/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.3554 - loss: 1.0979 - val_accuracy: 0.3400 - val_loss: 1.0978\n",
            "Epoch 7/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.2895 - loss: 1.1003 - val_accuracy: 0.3400 - val_loss: 1.0975\n",
            "Epoch 8/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.3295 - loss: 1.0994 - val_accuracy: 0.3400 - val_loss: 1.0975\n",
            "Epoch 9/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.3467 - loss: 1.0981 - val_accuracy: 0.3400 - val_loss: 1.0975\n",
            "Epoch 10/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.3306 - loss: 1.0994 - val_accuracy: 0.3450 - val_loss: 1.0973\n",
            "Epoch 11/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.3035 - loss: 1.1000 - val_accuracy: 0.3400 - val_loss: 1.0983\n",
            "Epoch 12/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.3690 - loss: 1.0978 - val_accuracy: 0.3400 - val_loss: 1.0979\n",
            "Epoch 13/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.3388 - loss: 1.0986 - val_accuracy: 0.3400 - val_loss: 1.0982\n",
            "Epoch 14/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.3540 - loss: 1.0973 - val_accuracy: 0.3600 - val_loss: 1.0978\n",
            "Epoch 15/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.3611 - loss: 1.0974 - val_accuracy: 0.3450 - val_loss: 1.0968\n",
            "Epoch 16/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.3502 - loss: 1.0982 - val_accuracy: 0.3450 - val_loss: 1.0984\n",
            "Epoch 17/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.3522 - loss: 1.0984 - val_accuracy: 0.3600 - val_loss: 1.0977\n",
            "Epoch 18/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.3352 - loss: 1.0982 - val_accuracy: 0.3650 - val_loss: 1.0971\n",
            "Epoch 19/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.3638 - loss: 1.0999 - val_accuracy: 0.3550 - val_loss: 1.0982\n",
            "Epoch 20/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.3487 - loss: 1.0976 - val_accuracy: 0.3650 - val_loss: 1.0976\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aab556ed390>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_lstm, y_lstm)\n",
        "print(\"\\nLSTM Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "818TCwBJQ8oJ",
        "outputId": "1d03b956-a32f-4b88-d6dd-7c9f23eadef2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3710 - loss: 1.0961\n",
            "\n",
            "LSTM Model Accuracy: 0.37299999594688416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "xgboost"
      ],
      "metadata": {
        "id": "ADu4ezUATzok"
      }
    }
  ]
}