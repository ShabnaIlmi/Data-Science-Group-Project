{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDBqzRDaflu/DH8pV9u0G4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShabnaIlmi/Data-Science-Group-Project/blob/recipe-risk-analyzer/DSGP_startover.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and Inspect the Data**"
      ],
      "metadata": {
        "id": "r5JpAA525fz1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59QL0yYX20_8",
        "outputId": "d185b7eb-d0cd-4256-d921-f39a62fccff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìå recipes_nodup.csv:\n",
            "   Recipe ID                                    Chemical Names  \\\n",
            "0          1               Ephedrine + Red Phosphorus + Iodine   \n",
            "1          2             Toluene + Nitric Acid + Sulfuric Acid   \n",
            "2          3       Hydrogen Peroxide + Acetone + Sulfuric Acid   \n",
            "3          4  Ephedrine + Potassium Permanganate + Acetic Acid   \n",
            "4          5             Potassium Nitrate + Charcoal + Sulfur   \n",
            "\n",
            "                     Formulas   Quantities (g/mL)  \\\n",
            "0           C10H15NO + P + I2     30g + 15g + 10g   \n",
            "1         C7H8 + HNO3 + H2SO4  50mL + 30mL + 40mL   \n",
            "2        H2O2 + C3H6O + H2SO4   20mL + 30mL + 5mL   \n",
            "3  C10H15NO + KMnO4 + CH3COOH    25g + 10g + 50mL   \n",
            "4                KNO3 + C + S     75g + 15g + 10g   \n",
            "\n",
            "                         CAS Numbers    Solvent Used  \\\n",
            "0   299-42-3 + 7723-14-0 + 7553-56-2  Acetone, Ether   \n",
            "1   108-88-3 + 7697-37-2 + 7664-93-9             NaN   \n",
            "2    7722-84-1 + 67-64-1 + 7664-93-9             NaN   \n",
            "3     299-42-3 + 7722-64-7 + 64-19-7           Water   \n",
            "4  7757-79-1 + 7440-44-0 + 7704-34-9           Water   \n",
            "\n",
            "               Reaction Conditions Toxicity Level Flammability (Yes/No)  \\\n",
            "0       Reduction reaction at 40¬∞C           High                   Yes   \n",
            "1                Nitration at 50¬∞C           High                   Yes   \n",
            "2         Acidic catalysis at 10¬∞C      Very High                   Yes   \n",
            "3  Oxidation reaction at room temp           High                    No   \n",
            "4              Grinding and mixing         Medium                    No   \n",
            "\n",
            "  Reactivity (Stable/Unstable)  ...  Environmental Hazard (Yes/No)  \\\n",
            "0                     Unstable  ...                            Yes   \n",
            "1                     Unstable  ...                            Yes   \n",
            "2                     Unstable  ...                            Yes   \n",
            "3                       Stable  ...                            Yes   \n",
            "4                       Stable  ...                            Yes   \n",
            "\n",
            "   Dual Use Potential (Yes/No)                  Intended Use  \\\n",
            "0                          Yes        Illegal drug synthesis   \n",
            "1                          Yes                 TNT synthesis   \n",
            "2                          Yes  Acetone Peroxide (Explosive)   \n",
            "3                          Yes       Methcathinone synthesis   \n",
            "4                          Yes      Fireworks & Black Powder   \n",
            "\n",
            "  Export Restriction (Yes/No) Controlled Substance (Yes/No)  \\\n",
            "0                         Yes                           Yes   \n",
            "1                         Yes                           Yes   \n",
            "2                         Yes                           Yes   \n",
            "3                         Yes                           Yes   \n",
            "4                         Yes                            No   \n",
            "\n",
            "  Risk Assessment Score (0-100) Regulatory Body  \\\n",
            "0                            95        DEA, FDA   \n",
            "1                            97        ATF, DOT   \n",
            "2                            99        ATF, DOT   \n",
            "3                            88        DEA, FDA   \n",
            "4                            70        ATF, DOT   \n",
            "\n",
            "   Compliance Status (Compliant/Non-compliant) Risk Category  \\\n",
            "0                                Non-compliant      Critical   \n",
            "1                                Non-compliant      Critical   \n",
            "2                                Non-compliant      Critical   \n",
            "3                                Non-compliant          High   \n",
            "4                                Non-compliant          High   \n",
            "\n",
            "  Risk Score (0-100)  \n",
            "0                 98  \n",
            "1                 99  \n",
            "2                 99  \n",
            "3                 90  \n",
            "4                 85  \n",
            "\n",
            "[5 rows x 22 columns] \n",
            "\n",
            "\n",
            "üìå chem.csv:\n",
            "   ID         Chemical name molarcular  formula  CAS number  \\\n",
            "0   1               Acetone                C3H6O    67-64-1   \n",
            "1   2             Acetylene                 C2H2    74-86-2   \n",
            "2   3         Acrylonitrile                C3H3N   107-13-1   \n",
            "3   4      Ammonium Nitrate               NH4NO3  6484-52-2   \n",
            "4   5  Ammonium Perchlorate              NH4ClO4  7790-98-9   \n",
            "\n",
            "                             applications  UN number       synonyms  \\\n",
            "0  Solvent, cleaning agent, paint thinner     1090.0      Propanone   \n",
            "1             Welding, chemical synthesis     1001.0         Ethyne   \n",
            "2            Plastic production, textiles     1093.0  Vinyl cyanide   \n",
            "3                  Fertilizer, explosives     1942.0         Nitram   \n",
            "4                 Rocket fuel, explosives     1442.0             AP   \n",
            "\n",
            "  Toxicity level  \n",
            "0            Low  \n",
            "1           High  \n",
            "2           High  \n",
            "3           High  \n",
            "4           High   \n",
            "\n",
            "\n",
            "üîç recipes_nodup.csv Shape: (76, 22)\n",
            "üîç chem.csv Shape: (401, 8)\n",
            "üõ† recipes_nodup Columns: Index(['Recipe ID', 'Chemical Names', 'Formulas', 'Quantities (g/mL)',\n",
            "       'CAS Numbers', 'Solvent Used', 'Reaction Conditions', 'Toxicity Level',\n",
            "       'Flammability (Yes/No)', 'Reactivity (Stable/Unstable)',\n",
            "       'Explosiveness (1-10)', 'Health Risk Score (0-100)',\n",
            "       'Environmental Hazard (Yes/No)', 'Dual Use Potential (Yes/No)',\n",
            "       'Intended Use', 'Export Restriction (Yes/No)',\n",
            "       'Controlled Substance (Yes/No)', 'Risk Assessment Score (0-100)',\n",
            "       'Regulatory Body', 'Compliance Status (Compliant/Non-compliant)',\n",
            "       'Risk Category', 'Risk Score (0-100)'],\n",
            "      dtype='object')\n",
            "üõ† chem Columns: Index(['ID', 'Chemical name', 'molarcular  formula ', 'CAS number',\n",
            "       'applications', 'UN number', 'synonyms', 'Toxicity level'],\n",
            "      dtype='object')\n",
            "‚ö†Ô∏è Missing values in recipes_nodup:\n",
            " Recipe ID                                       0\n",
            "Chemical Names                                  0\n",
            "Formulas                                        0\n",
            "Quantities (g/mL)                               0\n",
            "CAS Numbers                                     0\n",
            "Solvent Used                                   54\n",
            "Reaction Conditions                             0\n",
            "Toxicity Level                                  0\n",
            "Flammability (Yes/No)                           0\n",
            "Reactivity (Stable/Unstable)                    0\n",
            "Explosiveness (1-10)                            0\n",
            "Health Risk Score (0-100)                       0\n",
            "Environmental Hazard (Yes/No)                   0\n",
            "Dual Use Potential (Yes/No)                     0\n",
            "Intended Use                                    0\n",
            "Export Restriction (Yes/No)                     0\n",
            "Controlled Substance (Yes/No)                   0\n",
            "Risk Assessment Score (0-100)                   0\n",
            "Regulatory Body                                 0\n",
            "Compliance Status (Compliant/Non-compliant)     0\n",
            "Risk Category                                   0\n",
            "Risk Score (0-100)                              0\n",
            "dtype: int64 \n",
            "\n",
            "‚ö†Ô∏è Missing values in chem:\n",
            " ID                       0\n",
            "Chemical name            0\n",
            "molarcular  formula      0\n",
            "CAS number               1\n",
            "applications             0\n",
            "UN number               12\n",
            "synonyms                 6\n",
            "Toxicity level           0\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "recipes_path = \"/content/recipes_nodup.csv\"\n",
        "chem_path = \"/content/chem.csv\"\n",
        "\n",
        "df_recipes = pd.read_csv(recipes_path)\n",
        "df_chem = pd.read_csv(chem_path)\n",
        "\n",
        "# Display first few rows of each dataset\n",
        "print(\"üìå recipes_nodup.csv:\")\n",
        "print(df_recipes.head(), \"\\n\\n\")\n",
        "\n",
        "print(\"üìå chem.csv:\")\n",
        "print(df_chem.head(), \"\\n\\n\")\n",
        "\n",
        "# Check dataset shapes\n",
        "print(f\"üîç recipes_nodup.csv Shape: {df_recipes.shape}\")\n",
        "print(f\"üîç chem.csv Shape: {df_chem.shape}\")\n",
        "\n",
        "# Show column names\n",
        "print(\"üõ† recipes_nodup Columns:\", df_recipes.columns)\n",
        "print(\"üõ† chem Columns:\", df_chem.columns)\n",
        "\n",
        "# Check missing values\n",
        "print(\"‚ö†Ô∏è Missing values in recipes_nodup:\\n\", df_recipes.isnull().sum(), \"\\n\")\n",
        "print(\"‚ö†Ô∏è Missing values in chem:\\n\", df_chem.isnull().sum(), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types of columns\n",
        "print(\"üîç Data types in recipes_nodup.csv:\\n\", df_recipes.dtypes, \"\\n\")\n",
        "print(\"üîç Data types in chem.csv:\\n\", df_chem.dtypes, \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW-wqlN9Kn9y",
        "outputId": "b1ba4d15-462a-4d3d-a90f-093317b0218c"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Data types in recipes_nodup.csv:\n",
            " Recipe ID                                       int64\n",
            "Chemical Names                                 object\n",
            "Formulas                                       object\n",
            "Quantities (g/mL)                              object\n",
            "CAS Numbers                                    object\n",
            "Solvent Used                                   object\n",
            "Reaction Conditions                            object\n",
            "Toxicity Level                                 object\n",
            "Flammability (Yes/No)                          object\n",
            "Reactivity (Stable/Unstable)                   object\n",
            "Explosiveness (1-10)                            int64\n",
            "Health Risk Score (0-100)                       int64\n",
            "Environmental Hazard (Yes/No)                  object\n",
            "Dual Use Potential (Yes/No)                    object\n",
            "Intended Use                                   object\n",
            "Export Restriction (Yes/No)                    object\n",
            "Controlled Substance (Yes/No)                  object\n",
            "Risk Assessment Score (0-100)                   int64\n",
            "Regulatory Body                                object\n",
            "Compliance Status (Compliant/Non-compliant)    object\n",
            "Risk Category                                  object\n",
            "Risk Score (0-100)                              int64\n",
            "dtype: object \n",
            "\n",
            "üîç Data types in chem.csv:\n",
            " ID                        int64\n",
            "Chemical name            object\n",
            "molarcular  formula      object\n",
            "CAS number               object\n",
            "applications             object\n",
            "UN number               float64\n",
            "synonyms                 object\n",
            "Toxicity level           object\n",
            "dtype: object \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Missing Values and Remove Duplicates**"
      ],
      "metadata": {
        "id": "LNp5ghao5kZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìå Duplicate rows in recipes_nodup:\", df_recipes.duplicated().sum())\n",
        "print(\"üìå Duplicate rows in chem:\", df_chem.duplicated().sum())\n",
        "\n",
        "print(\"‚ö†Ô∏è Missing values in recipes_nodup:\\n\", df_recipes.isnull().sum(), \"\\n\")\n",
        "print(\"‚ö†Ô∏è Missing values in chem:\\n\", df_chem.isnull().sum(), \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S6wKOY03Dvu",
        "outputId": "f166574f-fa9a-4d99-cadc-46cda22ca890"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìå Duplicate rows in recipes_nodup: 0\n",
            "üìå Duplicate rows in chem: 0\n",
            "‚ö†Ô∏è Missing values in recipes_nodup:\n",
            " Recipe ID                                       0\n",
            "Chemical Names                                  0\n",
            "Formulas                                        0\n",
            "Quantities (g/mL)                               0\n",
            "CAS Numbers                                     0\n",
            "Solvent Used                                   54\n",
            "Reaction Conditions                             0\n",
            "Toxicity Level                                  0\n",
            "Flammability (Yes/No)                           0\n",
            "Reactivity (Stable/Unstable)                    0\n",
            "Explosiveness (1-10)                            0\n",
            "Health Risk Score (0-100)                       0\n",
            "Environmental Hazard (Yes/No)                   0\n",
            "Dual Use Potential (Yes/No)                     0\n",
            "Intended Use                                    0\n",
            "Export Restriction (Yes/No)                     0\n",
            "Controlled Substance (Yes/No)                   0\n",
            "Risk Assessment Score (0-100)                   0\n",
            "Regulatory Body                                 0\n",
            "Compliance Status (Compliant/Non-compliant)     0\n",
            "Risk Category                                   0\n",
            "Risk Score (0-100)                              0\n",
            "dtype: int64 \n",
            "\n",
            "‚ö†Ô∏è Missing values in chem:\n",
            " ID                       0\n",
            "Chemical name            0\n",
            "molarcular  formula      0\n",
            "CAS number               1\n",
            "applications             0\n",
            "UN number               12\n",
            "synonyms                 6\n",
            "Toxicity level           0\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display unique values for categorical columns\n",
        "print(\"Unique values in key columns (recipes_nodup):\\n\")\n",
        "for col in df_recipes.columns:\n",
        "    print(f\"{col}: {df_recipes[col].nunique()} unique values\")\n",
        "\n",
        "print(\"\\nüõ† Unique values in key columns (chem):\\n\")\n",
        "for col in df_chem.columns:\n",
        "    print(f\"{col}: {df_chem[col].nunique()} unique values\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqh7AbJcK0Vh",
        "outputId": "2539b0d9-aa07-4fb7-df69-b2429e1b47fd"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in key columns (recipes_nodup):\n",
            "\n",
            "Recipe ID: 76 unique values\n",
            "Chemical Names: 76 unique values\n",
            "Formulas: 75 unique values\n",
            "Quantities (g/mL): 57 unique values\n",
            "CAS Numbers: 76 unique values\n",
            "Solvent Used: 3 unique values\n",
            "Reaction Conditions: 37 unique values\n",
            "Toxicity Level: 3 unique values\n",
            "Flammability (Yes/No): 2 unique values\n",
            "Reactivity (Stable/Unstable): 3 unique values\n",
            "Explosiveness (1-10): 8 unique values\n",
            "Health Risk Score (0-100): 14 unique values\n",
            "Environmental Hazard (Yes/No): 1 unique values\n",
            "Dual Use Potential (Yes/No): 1 unique values\n",
            "Intended Use: 46 unique values\n",
            "Export Restriction (Yes/No): 2 unique values\n",
            "Controlled Substance (Yes/No): 2 unique values\n",
            "Risk Assessment Score (0-100): 13 unique values\n",
            "Regulatory Body: 5 unique values\n",
            "Compliance Status (Compliant/Non-compliant): 2 unique values\n",
            "Risk Category: 3 unique values\n",
            "Risk Score (0-100): 10 unique values\n",
            "\n",
            "üõ† Unique values in key columns (chem):\n",
            "\n",
            "ID: 401 unique values\n",
            "Chemical name: 393 unique values\n",
            "molarcular  formula : 376 unique values\n",
            "CAS number: 400 unique values\n",
            "applications: 343 unique values\n",
            "UN number: 332 unique values\n",
            "synonyms: 388 unique values\n",
            "Toxicity level: 4 unique values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing recipes_nodup.csv**"
      ],
      "metadata": {
        "id": "IXoian5rMyUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with \"Unknown\"\n",
        "df_recipes[\"Solvent Used\"].fillna(\"Unknown\", inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_itn-VWM0fR",
        "outputId": "bf499ea1-b1ab-4d75-8d5d-259ad3edc13c"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-311-d9d1a59aa268>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_recipes[\"Solvent Used\"].fillna(\"Unknown\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "df_recipes = pd.read_csv(recipes_path)\n",
        "\n",
        "# Function to combine chemicals with their quantities\n",
        "def combine_chemicals(row):\n",
        "    chemicals = row[\"Chemical Names\"].split(\" + \")\n",
        "    quantities = row[\"Quantities (g/mL)\"].split(\" + \")\n",
        "\n",
        "    combined = []\n",
        "    for chem, qty in zip(chemicals, quantities):\n",
        "        qty_numeric = re.sub(r\"[^\\d.]\", \"\", qty)  # Remove non-numeric characters\n",
        "        combined.append(f\"{chem}:{qty_numeric}\")  # Format as \"Chemical:Quantity\"\n",
        "\n",
        "    return \" + \".join(combined)  # Join all pairs into a single text format\n",
        "\n",
        "# Apply transformation\n",
        "df_recipes[\"Combined Recipe\"] = df_recipes.apply(combine_chemicals, axis=1)\n",
        "\n",
        "# Drop old columns\n",
        "df_recipes.drop(columns=[\"Chemical Names\", \"Quantities (g/mL)\"], inplace=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A0FPoXOm1EAQ"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode Categorical Features"
      ],
      "metadata": {
        "id": "uW_2fMnINDcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "binary_cols = [\n",
        "    \"Flammability (Yes/No)\", \"Reactivity (Stable/Unstable)\",\n",
        "    \"Environmental Hazard (Yes/No)\", \"Dual Use Potential (Yes/No)\",\n",
        "    \"Export Restriction (Yes/No)\", \"Controlled Substance (Yes/No)\",\n",
        "    \"Compliance Status (Compliant/Non-compliant)\"\n",
        "]\n",
        "\n",
        "# Convert Yes/No to 0/1\n",
        "for col in binary_cols:\n",
        "    df_recipes[col] = df_recipes[col].apply(lambda x: 1 if x in [\"Yes\", \"Compliant\", \"Stable\"] else 0)\n",
        "\n",
        "# Encode Risk Category\n",
        "df_recipes[\"Risk Category Encoded\"] = LabelEncoder().fit_transform(df_recipes[\"Risk Category\"])\n"
      ],
      "metadata": {
        "id": "IBRv4iCiNCRT"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Numerical Features"
      ],
      "metadata": {
        "id": "161lBd1GNPGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# Remove \"Total Quantity (g/mL)\" from num_cols as it is no longer present in df_recipes\n",
        "num_cols = [\"Risk Score (0-100)\", \"Health Risk Score (0-100)\", \"Risk Assessment Score (0-100)\"]\n",
        "\n",
        "df_recipes[num_cols] = scaler.fit_transform(df_recipes[num_cols])\n",
        "\n",
        "\n",
        "# Save processed data\n",
        "df_recipes.to_csv(\"/content/processed_recipes.csv\", index=False)\n",
        "print(\"‚úÖ Successfully converted recipes into structured format!\")"
      ],
      "metadata": {
        "id": "pI1nG4GiNSWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e9dde1-eaf0-4f67-eb18-cc8d84188884"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully converted recipes into structured format!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing chem.csv**"
      ],
      "metadata": {
        "id": "m6W3F3tUNvkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in chem.csv\n",
        "df_chem[\"CAS number\"].fillna(\"Unknown\", inplace=True)\n",
        "df_chem[\"UN number\"].fillna(\"Unknown\", inplace=True)\n",
        "df_chem[\"synonyms\"].fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# Standardize column names\n",
        "df_chem.columns = df_chem.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "# Save preprocessed chem.csv\n",
        "df_chem.to_csv(\"/content/preprocessed_chem.csv\", index=False)\n",
        "print(\"Preprocessed chem.csv saved!\")\n"
      ],
      "metadata": {
        "id": "fnn0olrMNzyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e79f9a1-d8ee-43de-8aa7-86597d2fd7a8"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed chem.csv saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-315-e602f27998e5>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_chem[\"CAS number\"].fillna(\"Unknown\", inplace=True)\n",
            "<ipython-input-315-e602f27998e5>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_chem[\"UN number\"].fillna(\"Unknown\", inplace=True)\n",
            "<ipython-input-315-e602f27998e5>:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df_chem[\"UN number\"].fillna(\"Unknown\", inplace=True)\n",
            "<ipython-input-315-e602f27998e5>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_chem[\"synonyms\"].fillna(\"Unknown\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Convert Recipes into Features***"
      ],
      "metadata": {
        "id": "bsidkfW25SRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert \"Combined Recipe\" into TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Keep top 500 most important features\n",
        "X_tfidf = vectorizer.fit_transform(df_recipes[\"Combined Recipe\"]).toarray()\n",
        "\n",
        "# Convert TF-IDF output to DataFrame and merge with other numerical features\n",
        "X_tfidf_df = pd.DataFrame(X_tfidf, columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Drop \"Combined Recipe\" and merge TF-IDF features\n",
        "df_final = pd.concat([df_recipes.drop(columns=[\"Combined Recipe\"]), X_tfidf_df], axis=1)\n",
        "\n",
        "print(\"‚úÖ TF-IDF transformation complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvjZUIHy6rFV",
        "outputId": "dbb4a8bd-f5b0-4699-b70d-09cc53484e89"
      },
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TF-IDF transformation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Define Label Encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit on the target variable (Risk Category)\n",
        "df_recipes[\"Risk Category Encoded\"] = label_encoder.fit_transform(df_recipes[\"Risk Category\"])\n",
        "\n",
        "# Save the trained LabelEncoder\n",
        "joblib.dump(label_encoder, \"risk_category_encoder.pkl\")\n",
        "\n",
        "print(\"‚úÖ Label Encoder saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vZiFz1IWIaV",
        "outputId": "d4c816e6-a617-4ef3-fd45-0f6d76df3d5b"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Label Encoder saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train ML Models**"
      ],
      "metadata": {
        "id": "_TIRdQzI5i9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "joblib.dump(scaler, \"minmax_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"risk_category_encoder.pkl\")\n",
        "\n",
        "print(\"‚úÖ Preprocessing models saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M0FGzjsWO7H",
        "outputId": "7733427d-537d-4474-df3f-69338999cbf1"
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Preprocessing models saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the trained vectorizer, scaler, and label encoders\n",
        "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
        "scaler = joblib.load(\"minmax_scaler.pkl\")\n",
        "label_encoder = joblib.load(\"risk_category_encoder.pkl\")\n",
        "\n",
        "def preprocess_new_input(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Convert \"Combined Recipe\" into structured format\n",
        "    if \"Combined Recipe\" in df.columns:\n",
        "        def combine_chemicals(row):\n",
        "            chemicals = row.split(\" + \")\n",
        "            combined = [f\"{chem.split(':')[0]}:{re.sub(r'[^0-9.]', '', chem.split(':')[1])}\" for chem in chemicals]\n",
        "            return \" + \".join(combined)\n",
        "\n",
        "        df[\"Combined Recipe\"] = df[\"Combined Recipe\"].apply(combine_chemicals)\n",
        "\n",
        "    # Convert categorical Yes/No features to 0/1\n",
        "    binary_cols = [\n",
        "        \"Flammability (Yes/No)\", \"Reactivity (Stable/Unstable)\",\n",
        "        \"Environmental Hazard (Yes/No)\", \"Dual Use Potential (Yes/No)\",\n",
        "        \"Export Restriction (Yes/No)\", \"Controlled Substance (Yes/No)\",\n",
        "        \"Compliance Status (Compliant/Non-compliant)\"\n",
        "    ]\n",
        "    for col in binary_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda x: 1 if x in [\"Yes\", \"Compliant\", \"Stable\"] else 0)\n",
        "\n",
        "    # Scale numerical columns\n",
        "    num_cols = [\"Risk Score (0-100)\", \"Health Risk Score (0-100)\", \"Risk Assessment Score (0-100)\"]\n",
        "    if set(num_cols).issubset(df.columns):\n",
        "        df[num_cols] = scaler.transform(df[num_cols])  # Apply trained scaler\n",
        "\n",
        "    # Transform text using trained TF-IDF vectorizer\n",
        "    if \"Combined Recipe\" in df.columns:\n",
        "        tfidf_features = vectorizer.transform(df[\"Combined Recipe\"]).toarray()\n",
        "        tfidf_df = pd.DataFrame(tfidf_features, columns=vectorizer.get_feature_names_out())\n",
        "        df = pd.concat([df.drop(columns=[\"Combined Recipe\"], errors=\"ignore\"), tfidf_df], axis=1)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "iqxH5YzzVm0N"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df_final.drop(columns=[\"Risk Category\", \"Risk Category Encoded\"])  # Features\n",
        "y = df_final[\"Risk Category Encoded\"]  # Target\n",
        "\n",
        "# Split into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"‚úÖ Data split complete! Ready for training.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJplhCOF5ox_",
        "outputId": "b43cc227-f05e-4335-cd05-3da59dc4abbe"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data split complete! Ready for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=100)\n",
        "\n",
        "# Transform text columns\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train[\"Formulas\"].fillna(\"\")).toarray()\n",
        "X_test_tfidf = vectorizer.transform(X_test[\"Formulas\"].fillna(\"\")).toarray()\n",
        "\n",
        "# Convert to DataFrame and merge\n",
        "X_train_tfidf_df = pd.DataFrame(X_train_tfidf, columns=vectorizer.get_feature_names_out())\n",
        "X_test_tfidf_df = pd.DataFrame(X_test_tfidf, columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "X_train = pd.concat([X_train.drop(columns=[\"Formulas\"]), X_train_tfidf_df], axis=1)\n",
        "X_test = pd.concat([X_test.drop(columns=[\"Formulas\"]), X_test_tfidf_df], axis=1)\n",
        "\n",
        "print(\"‚úÖ TF-IDF applied to text columns!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7810z9h59Zrk",
        "outputId": "4e02bf53-8493-45a2-a7cf-8dbf1359f64c"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TF-IDF applied to text columns!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(columns=[\"Formulas\", \"CAS Numbers\"], errors=\"ignore\")\n",
        "X_test = X_test.drop(columns=[\"Formulas\", \"CAS Numbers\"], errors=\"ignore\")\n",
        "\n",
        "print(\"‚úÖ Dropped Formulas & CAS Numbers (Not needed for model training).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7MWSpgd9P7g",
        "outputId": "281a9715-cf9f-4223-f78a-af05be6dfba8"
      },
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dropped Formulas & CAS Numbers (Not needed for model training).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine features and target into one DataFrame if not done already\n",
        "X = df_final.drop(columns=[\"Risk Category\", \"Risk Category Encoded\"])\n",
        "y = df_final[\"Risk Category Encoded\"]\n",
        "\n",
        "print(\"Before split - X shape:\", X.shape, \"y shape:\", y.shape)\n",
        "\n",
        "# Perform a stratified split to maintain class balance\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"After split - X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lezlj9QV1_rm",
        "outputId": "4d23056c-7123-4940-b662-63525aea16f9"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before split - X shape: (76, 120) y shape: (76,)\n",
            "After split - X_train shape: (60, 120) y_train shape: (60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# List of categorical columns\n",
        "cat_cols = [\"Solvent Used\", \"Reaction Conditions\", \"Toxicity Level\", \"Intended Use\", \"Regulatory Body\"]\n",
        "\n",
        "# Apply Label Encoding correctly\n",
        "for col in cat_cols:\n",
        "    encoder = LabelEncoder()\n",
        "\n",
        "    # Fit on both training & testing data\n",
        "    encoder.fit(pd.concat([X_train[col], X_test[col]], axis=0).astype(str))\n",
        "\n",
        "    # Transform both datasets\n",
        "    X_train[col] = encoder.transform(X_train[col].astype(str))\n",
        "    X_test[col] = encoder.transform(X_test[col].astype(str))\n",
        "\n",
        "print(\"‚úÖ Successfully encoded categorical columns!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDi4MzRKw0Vg",
        "outputId": "a5ce0cfc-b07f-421c-cf13-96b8efa92c17"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully encoded categorical columns!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîç Data Types in X_train:\\n\", X_train.dtypes[X_train.dtypes == \"object\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2GCCzh93Ld-",
        "outputId": "38a75f5c-34ad-4cf1-adb7-43a19303bee7"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Data Types in X_train:\n",
            " Formulas       object\n",
            "CAS Numbers    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = [\"Formulas\", \"CAS Numbers\"]  # Add any other text-based columns\n",
        "\n",
        "X_train = X_train.drop(columns=drop_cols, errors=\"ignore\")\n",
        "X_test = X_test.drop(columns=drop_cols, errors=\"ignore\")\n",
        "\n",
        "print(\"‚úÖ Removed text columns from training data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNhgGF8s3cxf",
        "outputId": "064528e9-bef7-46d2-ef87-57872be1d11a"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Removed text columns from training data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)\n",
        "\n",
        "print(\"‚úÖ Confirmed all features are numeric!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAIkKENc40UI",
        "outputId": "67f6426f-6e8d-4001-945f-f8fcd0c3fef8"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Confirmed all features are numeric!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Adjust SMOTE settings\n",
        "smote = SMOTE(random_state=42, k_neighbors=1)  # Reduce k_neighbors\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check new class distribution\n",
        "import numpy as np\n",
        "print(\"üìä Class distribution before SMOTE:\", dict(zip(*np.unique(y_train, return_counts=True))))\n",
        "print(\"üìä Class distribution after SMOTE:\", dict(zip(*np.unique(y_train_balanced, return_counts=True))))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACS-n7xpj2nn",
        "outputId": "f4b939c1-5a42-4239-ae49-8865ec8f9c06"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Class distribution before SMOTE: {0: 52, 1: 6, 2: 2}\n",
            "üìä Class distribution after SMOTE: {0: 52, 1: 52, 2: 52}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE with k_neighbors=1 to avoid errors\n",
        "smote = SMOTE(random_state=42, k_neighbors=1)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check new class distribution\n",
        "import numpy as np\n",
        "print(\"üìä Class distribution after SMOTE:\", dict(zip(*np.unique(y_train_balanced, return_counts=True))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC7N-z7emn5Z",
        "outputId": "67a0bbc6-4ef9-4dfd-c91c-0979edb51a8a"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Class distribution after SMOTE: {0: 52, 1: 52, 2: 52}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "borderline_smote = BorderlineSMOTE(random_state=42, k_neighbors=1)\n",
        "X_train_balanced, y_train_balanced = borderline_smote.fit_resample(X_train, y_train) '''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6Hb3kYyak70I",
        "outputId": "3cb8e44c-ecd6-426e-f463-49f797549e8d"
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' from imblearn.over_sampling import BorderlineSMOTE\\n\\nborderline_smote = BorderlineSMOTE(random_state=42, k_neighbors=1)\\nX_train_balanced, y_train_balanced = borderline_smote.fit_resample(X_train, y_train) '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"üìä Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"‚úÖ Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JmV2tWUwcRf",
        "outputId": "15fade2d-c172-4572-d52e-2c90a92f9f4a"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.97        14\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.88        16\n",
            "   macro avg       0.31      0.33      0.32        16\n",
            "weighted avg       0.82      0.88      0.84        16\n",
            "\n",
            "‚úÖ Random Forest Accuracy: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''best_rf = RandomForestClassifier(\n",
        "    **grid_search.best_params_,\n",
        "    class_weight=\"balanced\",  # Handle class imbalance\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_rf.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_best_rf = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"üìä Balanced Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_best_rf))\n",
        "print(\"‚úÖ Balanced Random Forest Accuracy:\", accuracy_score(y_test, y_pred_best_rf))'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "F08tjCfBv30a",
        "outputId": "4c4f1c99-753a-4c87-948c-e47f241675be"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_rf = RandomForestClassifier(\\n    **grid_search.best_params_,\\n    class_weight=\"balanced\",  # Handle class imbalance\\n    random_state=42\\n)\\n\\nbest_rf.fit(X_train_balanced, y_train_balanced)\\n\\n# Make predictions\\ny_pred_best_rf = best_rf.predict(X_test)\\n\\n# Evaluate performance\\nprint(\"üìä Balanced Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_best_rf))\\nprint(\"‚úÖ Balanced Random Forest Accuracy:\", accuracy_score(y_test, y_pred_best_rf))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM FORREST OPTIMIZED\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_search.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "print(\"‚úÖ Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Train optimized model\n",
        "best_rf = RandomForestClassifier(**grid_search.best_params_, random_state=42)\n",
        "best_rf.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_best_rf = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"üìä Optimized Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_best_rf))\n",
        "print(\"‚úÖ Optimized Random Forest Accuracy:\", accuracy_score(y_test, y_pred_best_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEGrZLQklmow",
        "outputId": "c4a72a1a-5716-4d8f-90ab-e0deb7f256e2"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "üìä Optimized Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.97        14\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.94        16\n",
            "   macro avg       0.64      0.67      0.66        16\n",
            "weighted avg       0.88      0.94      0.91        16\n",
            "\n",
            "‚úÖ Optimized Random Forest Accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', scale_pos_weight=10, random_state=42)\n",
        "xgb_model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "print(\"üìä XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
        "print(\"‚úÖ XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jglR9iCemtAn",
        "outputId": "567c271f-d32a-4f5c-98d2-7bedc848ef37"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96        14\n",
            "           1       0.50      1.00      0.67         1\n",
            "           2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.94        16\n",
            "   macro avg       0.83      0.98      0.88        16\n",
            "weighted avg       0.97      0.94      0.95        16\n",
            "\n",
            "‚úÖ XGBoost Accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:20:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Train and save model\n",
        "rf_model.fit(X_train_balanced, y_train_balanced)\n",
        "joblib.dump(rf_model, \"random_forest_risk_model.pkl\")\n",
        "\n",
        "xgb_model.fit(X_train_balanced, y_train_balanced)\n",
        "joblib.dump(xgb_model, \"xgboost_risk_model.pkl\")\n",
        "\n",
        "print(\"‚úÖ Models saved successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGSGdadQFE_r",
        "outputId": "6aaadbd4-f294-4c6d-b319-1a4221ccad19"
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Models saved successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:20:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(xgb_model, X_train_balanced, y_train_balanced, cv=5, scoring=\"accuracy\")\n",
        "\n",
        "print(\"üìä Cross-Validation Accuracy Scores:\", cv_scores)\n",
        "print(\"‚úÖ Average Accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iORXL3OFHp7",
        "outputId": "39c6583a-eca6-4c9f-a9f8-e45c4501215c"
      },
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:20:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:20:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:20:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:20:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:20:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Cross-Validation Accuracy Scores: [0.90625    1.         1.         1.         0.96774194]\n",
            "‚úÖ Average Accuracy: 0.9747983870967742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained models\n",
        "rf_model = joblib.load(\"random_forest_risk_model.pkl\")\n",
        "xgb_model = joblib.load(\"xgboost_risk_model.pkl\")\n",
        "\n",
        "# Example new recipe input\n",
        "new_recipe = pd.DataFrame({\n",
        "    \"Combined Recipe\": [\"Water:500 + water:200 + water:50\"],\n",
        "    \"Flammability (Yes/No)\": [0],\n",
        "    \"Reactivity (Stable/Unstable)\": [0],\n",
        "    \"Explosiveness (1-10)\": [0],\n",
        "    \"Health Risk Score (0-100)\": [0],\n",
        "    \"Risk Score (0-100)\": [0]\n",
        "})\n",
        "\n",
        "# Apply preprocessing\n",
        "new_recipe_processed = preprocess_new_input(new_recipe)\n",
        "\n",
        "# Ensure new data matches training features\n",
        "missing_cols = set(X_train.columns) - set(new_recipe_processed.columns)\n",
        "for col in missing_cols:\n",
        "    new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
        "\n",
        "new_recipe_processed = new_recipe_processed[X_train.columns]  # Reorder columns\n",
        "\n",
        "# Predict risk category\n",
        "predicted_risk = xgb_model.predict(new_recipe_processed)\n",
        "predicted_risk_label = label_encoder.inverse_transform(predicted_risk)\n",
        "\n",
        "print(\"üîç Predicted Risk Category:\", predicted_risk_label[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxeRTCTgFLtD",
        "outputId": "64c3f9ae-097a-4ffe-9855-ea45fe2c0cbf"
      },
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Predicted Risk Category: Medium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n",
            "<ipython-input-338-e5f811336ac7>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  new_recipe_processed[col] = 0  # Add missing columns as zeros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_features = vectorizer.transform(new_recipe[\"Combined Recipe\"]).toarray()\n",
        "print(\"üîç TF-IDF Feature Vector:\", tfidf_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYn8NKi0YHeN",
        "outputId": "301683ce-8b38-46a9-faea-9b52efb979fa"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç TF-IDF Feature Vector: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    }
  ]
}