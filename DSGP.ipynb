{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEWNPJCfPZtE68g+HbVjNA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShabnaIlmi/Data-Science-Group-Project/blob/main/DSGP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n"
      ],
      "metadata": {
        "id": "Dxv5RWe_xE-u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = \"chemical_recipe_dataset.csv\"  # Replace with the actual file path if necessary\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vessNO4bxFs0",
        "outputId": "80484757-614f-45f5-a29c-dfda7f91d7bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Recipe ID                                     Chemical Names  \\\n",
            "0     R0001  Acetone + Hydrogen Peroxide + Sulfuric Acid + ...   \n",
            "1     R0002              Charcoal + Potassium Nitrate + Sulfur   \n",
            "2     R0003                         Hydrogen Sulfide + Ammonia   \n",
            "3     R0004                          Sulfur + Ammonium Nitrate   \n",
            "4     R0005    Hydrogen Sulfide + Ammonia + Methane + Chlorine   \n",
            "\n",
            "                  Quantities   Category  \\\n",
            "0  485g + 398g + 275g + 197g  Explosive   \n",
            "1          465g + 134g + 72g  Explosive   \n",
            "2                272g + 358g  Corrosive   \n",
            "3                297g + 304g   Unstable   \n",
            "4   74g + 376g + 285g + 199g  Corrosive   \n",
            "\n",
            "                                 Potential Reaction Risk Level  \n",
            "0   Explosion risk when exposed to heat or friction        Low  \n",
            "1   Explosion risk when exposed to heat or friction     Medium  \n",
            "2                    Causes severe burns on contact     Medium  \n",
            "3  May decompose violently under certain conditions       High  \n",
            "4                    Causes severe burns on contact     Medium  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the 'Risk Level' (target variable)\n",
        "label_encoder = LabelEncoder()\n",
        "data['Risk Level Encoded'] = label_encoder.fit_transform(data['Risk Level'])\n",
        "\n",
        "# One-hot encode the 'Chemical Names' and 'Category'\n",
        "chemical_dummies = data['Chemical Names'].str.get_dummies(sep=' + ')\n",
        "category_dummies = data['Category'].str.get_dummies(sep=', ')\n",
        "\n",
        "# Extract numerical values from 'Quantities' (sum the grams for simplicity)\n",
        "data['Total Quantity (g)'] = data['Quantities'].str.extractall(r'(\\d+)').astype(int).groupby(level=0).sum()\n",
        "\n",
        "# Combine all features\n",
        "X = pd.concat([chemical_dummies, category_dummies, data['Total Quantity (g)']], axis=1)\n",
        "y = data['Risk Level Encoded']\n"
      ],
      "metadata": {
        "id": "cDAhdjzExKiF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data first\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Apply SMOTE only to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Original class distribution: {dict(zip(*np.unique(y_train, return_counts=True)))}\")\n",
        "print(f\"Balanced class distribution: {dict(zip(*np.unique(y_train_balanced, return_counts=True)))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfVL1zx9yini",
        "outputId": "e471afc0-a704-4101-ff5f-324bfe874afa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution: {0: 272, 1: 270, 2: 258}\n",
            "Balanced class distribution: {0: 272, 1: 272, 2: 272}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "yJWc1LSSxOA1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Perform RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf, param_distributions=param_distributions,\n",
        "    n_iter=50, cv=3, scoring='accuracy', random_state=42, n_jobs=-1\n",
        ")\n",
        "random_search.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", random_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZggJaOTO0Y9C",
        "outputId": "9ace65ae-7a19-4451-d797-13237126bceb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 10}\n",
            "Best Cross-Validation Accuracy: 0.36642156862745096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances and select top features\n",
        "# Use random_search.best_estimator_ to access the fitted model\n",
        "importances = random_search.best_estimator_.feature_importances_\n",
        "important_indices = np.argsort(importances)[-10:]  # Top 10 features\n",
        "X_selected = X.iloc[:, important_indices]\n",
        "\n",
        "print(\"Top Features:\", X.columns[important_indices])\n",
        "\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "id": "QOPI8ZVdxQet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6822adff-ccd1-4bbd-c66b-ac103d8feba0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Features: Index([' + Chlorine + Ammonia + Methane + ',\n",
            "       ' + Chlorine + Ammonia + Methane + Hydrogen Sulfide + ',\n",
            "       ' + Chlorine + Hydrogen Sulfide + ',\n",
            "       ' + Charcoal + Sulfur + Ammonium Nitrate + ', 'Flammable', 'Toxic',\n",
            "       'Corrosive', 'Explosive', 'Unstable', 'Total Quantity (g)'],\n",
            "      dtype='object')\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "v4CMhlsCxSdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1ecf44-cfdb-46b3-a075-eb521b9f21a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[16 26 20]\n",
            " [23 18 30]\n",
            " [32 21 14]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.26      0.24        62\n",
            "           1       0.28      0.25      0.26        71\n",
            "           2       0.22      0.21      0.21        67\n",
            "\n",
            "    accuracy                           0.24       200\n",
            "   macro avg       0.24      0.24      0.24       200\n",
            "weighted avg       0.24      0.24      0.24       200\n",
            "\n",
            "\n",
            "Accuracy Score: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(model, \"risk_prediction_model.pkl\")\n",
        "print(\"Model saved as 'risk_prediction_model.pkl'\")\n"
      ],
      "metadata": {
        "id": "Pk1BwUepxVeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e35d4e-2c19-4b89-9b34-6ded2e60b996"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'risk_prediction_model.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Predict risk for a new chemical combination\n",
        "new_data = pd.DataFrame({\n",
        "    \"Chemical Names\": [\"Ammonium Nitrate + Hydrogen Peroxide\"],\n",
        "    \"Category\": [\"Explosive, Toxic Liquid\"],\n",
        "    \"Quantities\": [\"200g + 100g\"]\n",
        "})\n",
        "\n",
        "# Preprocess the new data\n",
        "new_data['Total Quantity (g)'] = new_data['Quantities'].str.extractall(r'(\\d+)').astype(int).groupby(level=0).sum()\n",
        "\n",
        "# Create dummy features matching training data\n",
        "chemical_features = pd.DataFrame(columns=chemical_dummies.columns)\n",
        "category_features = pd.DataFrame(columns=category_dummies.columns)\n",
        "\n",
        "# Fill in the matching dummy values\n",
        "for col in chemical_features.columns:\n",
        "    chemical_features.at[0, col] = 1 if col in new_data['Chemical Names'][0].split(\" + \") else 0\n",
        "\n",
        "for col in category_features.columns:\n",
        "    category_features.at[0, col] = 1 if col in new_data['Category'][0].split(\", \") else 0\n",
        "\n",
        "# Combine all features\n",
        "new_features = pd.concat([chemical_features, category_features], axis=1)\n",
        "new_features['Total Quantity (g)'] = new_data['Total Quantity (g)']\n",
        "\n",
        "# Fill missing columns with zeros to match training data\n",
        "new_features = new_features.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "# Standardize\n",
        "new_features_scaled = scaler.transform(new_features)\n",
        "\n",
        "# Predict\n",
        "predicted_risk = model.predict(new_features_scaled)\n",
        "predicted_risk_label = label_encoder.inverse_transform(predicted_risk)\n",
        "\n",
        "print(\"Predicted Risk Level:\", predicted_risk_label[0])\n"
      ],
      "metadata": {
        "id": "qAWTudRIyCel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4cef44d-1fa0-43c1-9b5d-6c06c27712e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Risk Level: Low\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained scaler and label encoder\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")\n"
      ],
      "metadata": {
        "id": "nhOCzZsbzXE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9f9f7e-3cc9-4b85-c88b-45fc505019ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load the previously trained model and preprocessing objects\n",
        "import joblib\n",
        "model = joblib.load(\"risk_prediction_model.pkl\")  # Load your trained model\n",
        "scaler = joblib.load(\"scaler.pkl\")  # Assuming you saved the scaler\n",
        "label_encoder = joblib.load(\"label_encoder.pkl\")  # Assuming you saved the label encoder\n",
        "\n",
        "# Define function to process input chemicals and make prediction\n",
        "def predict_chemical_risk(chemical_names, quantities, categories):\n",
        "    # Creating the dataframe from the input\n",
        "    input_data = pd.DataFrame({\n",
        "        \"Chemical Names\": [chemical_names],\n",
        "        \"Quantities\": [quantities],\n",
        "        \"Category\": [categories]\n",
        "    })\n",
        "\n",
        "    # Extracting and summing the quantities\n",
        "    input_data['Total Quantity (g)'] = input_data['Quantities'].str.extractall(r'(\\d+)').astype(int).groupby(level=0).sum()\n",
        "\n",
        "    # Creating feature columns for one-hot encoding\n",
        "    chemical_features = pd.DataFrame(columns=chemical_dummies.columns)\n",
        "    category_features = pd.DataFrame(columns=category_dummies.columns)\n",
        "\n",
        "    # Fill the chemical features based on input data\n",
        "    for col in chemical_features.columns:\n",
        "        chemical_features.at[0, col] = 1 if col in chemical_names.split(\" + \") else 0\n",
        "\n",
        "    # Fill the category features based on input data\n",
        "    for col in category_features.columns:\n",
        "        category_features.at[0, col] = 1 if col in categories.split(\", \") else 0\n",
        "\n",
        "    # Combine the features\n",
        "    new_features = pd.concat([chemical_features, category_features], axis=1)\n",
        "    new_features['Total Quantity (g)'] = input_data['Total Quantity (g)']\n",
        "\n",
        "    # Fill any missing columns from the training data\n",
        "    new_features = new_features.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Standardize the new data using the same scaler\n",
        "    new_features_scaled = scaler.transform(new_features)\n",
        "\n",
        "    # Predict risk\n",
        "    predicted_risk = model.predict(new_features_scaled)\n",
        "    predicted_risk_label = label_encoder.inverse_transform(predicted_risk)\n",
        "\n",
        "    return predicted_risk_label[0]\n",
        "\n",
        "# Example usage\n",
        "chemical_input = input(\"Enter chemical names (separate by ' + '): \")\n",
        "quantity_input = input(\"Enter quantities (separate by ' + '): \")\n",
        "category_input = input(\"Enter categories (separate by ', '): \")\n",
        "\n",
        "predicted_risk = predict_chemical_risk(chemical_input, quantity_input, category_input)\n",
        "\n",
        "print(\"Predicted Risk Level:\", predicted_risk)\n"
      ],
      "metadata": {
        "id": "JZn_ahc0y0PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_balanced)  # Scale only for XGBoost\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iowdo1mead9t",
        "outputId": "610e2014-f13d-4060-8d0a-9b0e0cc0c102"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=10,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "xgb_model.fit(X_train_scaled, y_train_balanced)  # Use scaled data for XGBoost\n",
        "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "BVCIUvGUszt2",
        "outputId": "7802625c-4fca-4fc9-9ff6-9fe1f6077f29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.26      0.24        62\n",
            "           1       0.28      0.25      0.26        71\n",
            "           2       0.22      0.21      0.21        67\n",
            "\n",
            "    accuracy                           0.24       200\n",
            "   macro avg       0.24      0.24      0.24       200\n",
            "weighted avg       0.24      0.24      0.24       200\n",
            "\n",
            "Accuracy Score: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=50, cv=5, scoring='accuracy', n_jobs=-1, random_state=42\n",
        ")\n",
        "random_search.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "best_rf = random_search.best_estimator_  # Use best RF model\n",
        "print(\"Best Random Forest Parameters:\", random_search.best_params_)\n"
      ],
      "metadata": {
        "id": "izYdKIcCwHjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3565b813-f4e9-4344-d7cf-1f39f51aefa1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall -y scikit-learn imbalanced-learn xgboost\n",
        "\n",
        "#!pip install -U scikit-learn==1.2.2 imbalanced-learn==0.11.0 xgboost==1.7.3\n"
      ],
      "metadata": {
        "id": "0X1TAPozcSb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.set_params(verbosity=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "RFqvwXg_eqjH",
        "outputId": "b1094759-a59b-48d8-d872-6bb63c84ac4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective='multi:softprob', predictor=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_model.fit(X_train_balanced, y_train_balanced)\n",
        "xgb_model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('rf', rf_model), ('xgb', xgb_model)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train_balanced, y_train_balanced)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "k3oZxWZid5ef",
        "outputId": "27deecd0-7f38-47a1-9e7b-086e5267fab9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
              "                             ('xgb',\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=None, grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=None, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=None,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=100, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            objective='multi:softprob',\n",
              "                                            predictor=None, ...))],\n",
              "                 voting='soft')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
              "                             (&#x27;xgb&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=None, grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=None, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=None,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=100, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            objective=&#x27;multi:softprob&#x27;,\n",
              "                                            predictor=None, ...))],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
              "                             (&#x27;xgb&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=None, grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=None, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=None,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=100, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            objective=&#x27;multi:softprob&#x27;,\n",
              "                                            predictor=None, ...))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Ensure XGBoost is compatible\n",
        "xgb_model.set_params(verbosity=0)\n",
        "\n",
        "# Create Voting Classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', best_rf),  # Best Random Forest model\n",
        "        ('xgb', xgb_model)  # XGBoost\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# Fit the classifier\n",
        "voting_clf.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_voting = voting_clf.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2JIMseia4_Q",
        "outputId": "a16a2df6-ef36-400c-db18-bbe8bcd91a44"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, best_rf.predict(X_test)))\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred_voting))\n",
        "\n",
        "print(\"\\nRandom Forest Report:\\n\", classification_report(y_test, best_rf.predict(X_test)))\n",
        "print(\"\\nXGBoost Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
        "print(\"\\nVoting Classifier Report:\\n\", classification_report(y_test, y_pred_voting))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuT2PIdFbg5k",
        "outputId": "324af6d1-e23c-4bc3-83ea-fce1ac7d61ff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.38\n",
            "XGBoost Accuracy: 0.355\n",
            "Voting Classifier Accuracy: 0.38\n",
            "\n",
            "Random Forest Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.18      0.23        62\n",
            "           1       0.45      0.24      0.31        71\n",
            "           2       0.38      0.72      0.49        67\n",
            "\n",
            "    accuracy                           0.38       200\n",
            "   macro avg       0.38      0.38      0.34       200\n",
            "weighted avg       0.38      0.38      0.35       200\n",
            "\n",
            "\n",
            "XGBoost Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.37      0.34        62\n",
            "           1       0.00      0.00      0.00        71\n",
            "           2       0.38      0.72      0.49        67\n",
            "\n",
            "    accuracy                           0.36       200\n",
            "   macro avg       0.23      0.36      0.28       200\n",
            "weighted avg       0.22      0.35      0.27       200\n",
            "\n",
            "\n",
            "Voting Classifier Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.18      0.23        62\n",
            "           1       0.45      0.24      0.31        71\n",
            "           2       0.38      0.72      0.49        67\n",
            "\n",
            "    accuracy                           0.38       200\n",
            "   macro avg       0.38      0.38      0.34       200\n",
            "weighted avg       0.38      0.38      0.35       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  StrOptions({\"micro\", \"macro\", \"samples\", \"weighted\", \"binary\"}),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  StrOptions({\"micro\", \"macro\", \"samples\", \"weighted\", \"binary\"}),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  StrOptions({\"micro\", \"macro\", \"samples\", \"weighted\", \"binary\"}),\n"
          ]
        }
      ]
    }
  ]
}